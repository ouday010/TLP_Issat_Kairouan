import streamlit as st
import io
import nltk 
from pypdf import PdfReader
from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.lsa import LsaSummarizer
from sumy.nlp.stemmers import Stemmer

# --- Configuration de la page Streamlit ---
st.set_page_config(
    page_title="üéì Synth√®se de Cours Local (Sumy)",
    layout="wide"
)

# --- Initialisation des D√©pendances NLTK ---
@st.cache_resource
def download_nltk_resources():
    """T√©l√©charge les ressources NLTK 'punkt' n√©cessaires √† Sumy pour le fran√ßais."""
    try:
        # st.toast("V√©rification et t√©l√©chargement des d√©pendances linguistiques NLTK...", icon="üõ†Ô∏è")
        nltk.download('punkt', quiet=True)
        nltk.download('punkt_tab', quiet=True) 
        return True
    except Exception as e:
        st.error(f"Erreur lors du t√©l√©chargement des ressources NLTK. D√©tails : {e}")
        return False

if not download_nltk_resources():
    st.stop()
else:
    st.sidebar.success("‚úÖ D√©pendances linguistiques NLTK charg√©es.")

# --- Constantes et Configuration ---
LANGUAGE = "french"
SENTENCES_COUNT = 10 
STEMMER = Stemmer(LANGUAGE)

# --- Fonction d'Extraction de Texte ---
@st.cache_data
def extract_text_from_pdf(uploaded_file):
    """Extrait tout le texte d'un fichier PDF."""
    st.info("Extraction du texte √† partir du PDF...")
    try:
        reader = PdfReader(io.BytesIO(uploaded_file.read()))
        text = ""
        for page_num, page in enumerate(reader.pages):
            text += page.extract_text() or f" [PAGE {page_num + 1} SANS TEXTE] "
        
        if len(text.strip()) < 100:
             st.error("Le PDF semble √™tre bas√© sur des images (scann√©) et ne contient pas de texte lisible. Veuillez utiliser un PDF avec du texte s√©lectionnable.")
             return None
        
        return text
    except Exception as e:
        st.error(f"Erreur fatale lors de l'extraction du texte : {e}")
        return None

# --- Fonction de R√©sum√© (Sumy) ---
def summarize_text_with_sumy(text, sentences_count=SENTENCES_COUNT):
    """Utilise l'algorithme LSA de Sumy pour g√©n√©rer un r√©sum√© extractif."""
    parser = PlaintextParser.from_string(text, Tokenizer(LANGUAGE))
    summarizer = LsaSummarizer(STEMMER)
    summary_sentences = summarizer(parser.document, sentences_count)
    
    # Retourne une liste Python des phrases. Streamlit les affichera mieux ainsi.
    summary_list = [str(sentence) for sentence in summary_sentences]
    return summary_list # ON RETOURNE UNE LISTE, PAS UNE CHA√éNE

# --- Interface Utilisateur (UX) Streamlit (Mobile Friendly) ---
def main():
    st.markdown("<h1 style='text-align: center;'>üìö Synth√®se de Cours Local (Sumy)</h1>", unsafe_allow_html=True)
    st.markdown("<p style='text-align: center;'>Solution rapide et locale (sans API) pour r√©sumer vos PDF.</p>", unsafe_allow_html=True)

    st.markdown("---") 

    # 1. Widget de t√©l√©versement
    with st.container(border=True):
        uploaded_file = st.file_uploader("‚û°Ô∏è 1. Choisissez votre fichier PDF de cours", type="pdf")
    
    if uploaded_file is not None:
        st.success(f"Fichier charg√© : **{uploaded_file.name}**")
        
        # 2. Param√®tres du R√©sum√©
        st.subheader("2. Param√®tres du R√©sum√©")
        sentences_count_slider = st.slider(
            "Nombre d'id√©es/phrases cl√©s souhait√©es :",
            min_value=5, max_value=25, value=SENTENCES_COUNT, step=1
        )
        
        st.markdown("---")
        
        # 3. Bouton d'action centr√© et clair
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            if st.button("üöÄ G√©n√©rer le R√©sum√© du Cours", use_container_width=True):
                
                # --- √âtape 1 : Extraction ---
                text_content = extract_text_from_pdf(uploaded_file)
                
                if not text_content:
                    return
                
                # --- √âtape 2 : R√©sum√© ---
                with st.spinner(f"‚è≥ L'algorithme LSA s√©lectionne les {sentences_count_slider} phrases les plus importantes..."):
                    # summary_result est d√©sormais une LISTE de phrases
                    summary_list = summarize_text_with_sumy(text_content, sentences_count_slider)
                
                # --- √âtape 3 : Affichage du R√©sultat ---
                st.subheader("‚úÖ R√©sultat de la Synth√®se")
                
                st.info("""
                **Rappel :** Ce r√©sum√© est **extractif** (il ne r√©√©crit pas le texte). Il est tr√®s rapide mais n'a pas la qualit√© d'une IA (LLM).
                """)
                
                st.markdown(
                    f"#### R√©sum√© Final ({sentences_count_slider} points cl√©s) :", 
                    unsafe_allow_html=True
                )
                
                # NOUVEL AFFICHAGE : Utilisation de st.markdown avec une liste non ordonn√©e
                st.markdown(
                    f'<div style="border: 1px solid #ddd; padding: 15px; border-radius: 5px; background-color: #f9f9f9; color: #333;"><ul>' 
                    + "".join([f'<li>{phrase}</li>' for phrase in summary_list]) 
                    + '</ul></div>',
                    unsafe_allow_html=True
                )
                st.balloons() 

    # Footer
    st.markdown("---")
    st.caption("Ce projet est un prototype simple pour localhost. Pour une int√©gration web professionnelle (React), il faudrait une architecture API (FastAPI) pour le back-end Python.")


if __name__ == "__main__":
    main()